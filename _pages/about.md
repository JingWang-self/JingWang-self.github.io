---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "<https://cdn.jsdelivr.net/gh/>" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "<https://raw.githubusercontent.com/>" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a first-year Ph.D. student at the [Institute for Visual Technology](https://idm.pku.edu.cn/) supervised by [Prof. Ruiqin Xiong](https://xiongrq.github.io/) at [Peking University](https://www.pku.edu.cn/). I received a bachelor's degree in Computer Science from the [Chongqing University](https://www.cqu.edu.cn/). During my undergraduate studies, I had the privilege of working with [Prof. Fuqiang Gu](https://faculty.cqu.edu.cn/gufq/zh_CN/index.htm) on the topic of robotics/SLAM.

[CV_Chinese](CV_Chinese_Jing Wang.pdf) / [CV_English](CV_English_Jing Wang.pdf)

**<font color='red'>My research interest includes multimodal learning, vision-language models and video understanding.</font>**

# üî• News
- *2025.06*: &nbsp;üéâüéâ One paper (SAMPLE: Semantic Alignment through Temporal-Adaptive Multimodal Prompt Learning for Event-Based Open-Vocabulary Action Recognition) has been accepted by *ICCV-2025* as first author!

# üìù Publications

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2025</div><img src='images/SAMPLE.png' alt="sym" width="120%"></div></div>
<div class='paper-box-text' markdown="1">

[Semantic Alignment through Temporal-Adaptive Multimodal Prompt Learning for Event-Based Open-Vocabulary Action Recognition](https://openaccess.thecvf.com/content/ICCV2025/papers/Wang_Semantic_Alignment_through_Temporal-Adaptive_Multimodal_Prompt_Learning_for_Event-Based_Open-Vocabulary_Action_ICCV_2025_paper.pdf)

**<font color='red'>Jing Wang</font>**, Rui Zhao, Ruiqin Xiong, Xingtao Wang, Xiaopeng Fan, and Tiejun Huang
**ICCV 2025**


[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

- Our work, SAMPLE, enables large vision-language models like CLIP to perform event-based open-vocabulary action recognition. By pioneering a Temporal-Adaptive Multimodal Prompt Learning strategy, it efficiently bridges the domain gap from static images to dynamic event streams while preserving generalization for unseen actions. This establishes a new state-of-the-art across all tested scenarios, from fully-supervised to zero-shot settings.

</div>
</div>



# üéñ Selected Honors and Awards

- *2024.05* Outstanding Undergraduate Graduate of Chongqing City.
- *2023.05* Advanced Individual in Science and Technology of Chongqing City.
- *2022.12* The National Second Prize **(Top 2.4%)** in the 2022 National College Student Mathematical Contest in Modeling (CUMCM), the Chinese Association of Mathematics and Applied Mathematics.
- *2022.05* Finalist Winner **(Top 2.5%)** in the 2022 Mathmatical Contest in Modeling (MCM/ICM), the COMAP of America.
- *2022.09* The National Scholarship for Bachelor Students.
- *2021.09* The National Scholarship for Bachelor Students.

# üìñ Educations

- *2024.09 - 2029.04 (expected)*, Peking University, Computer Science and Technology, Ph.D.
- *2020.09 - 2024.06*, Chongqing University, Computer Science and Technology, Bachelor.

# üíª Internships

- *2023.10 - 2024.03*, Research Intern - Applied Large Language Models, Shanghai AI Lab, China.
